{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert模型\n",
    "\n",
    "### BertConfig/BertTokenizer/BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertTokenizer, TFBertModel\n",
    "\n",
    "config = BertConfig()\n",
    "print(\"vocab_size: %d\" % config.vocab_size)\n",
    "print(\"hidden_size: %d\" % config.hidden_size)\n",
    "print(\"num_hidden_layers: %d\" % config.num_hidden_layers)\n",
    "print(\"num_attention_heads: %d\" % config.num_attention_heads)\n",
    "print(\"feed-forward dim: %d\" % config.intermediate_size)\n",
    "print(\"non-linear activation function: %s\" % config.hidden_act)\n",
    "print(\"max_position_embeddings: %d\" % config.max_position_embeddings)\n",
    "print(\"position_embedding_type: %s\" % config.position_embedding_type)\n",
    "print(\"type_vocab_size: %d\" % config.type_vocab_size)\n",
    "print()\n",
    "\n",
    "BertTokenizer.vocab_size\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "print(\"cls token: %s, id: %d\" % (tokenizer.cls_token, tokenizer.cls_token_id))\n",
    "print(\"sep token: %s, id: %d\" % (tokenizer.sep_token, tokenizer.sep_token_id))\n",
    "print(\"mask token: %s, id: %d\" % (tokenizer.mask_token, tokenizer.mask_token_id))\n",
    "print(\"unk token: %s, id: %d\" % (tokenizer.unk_token, tokenizer.unk_token_id))\n",
    "print(\"pad token: %s, id: %d\" % (tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "print(\"all_special_ids: %s\" % tokenizer.all_special_ids)\n",
    "\n",
    "print(\"vocab_size: %d\" % tokenizer.vocab_size)\n",
    "# vocab = tokenizer.get_vocab()\n",
    "\n",
    "print(tokenizer([\"Hello Wolrd\", \"你好，世界\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从Bert中提取嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "model = TFBertModel.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "# BertTokenizer.batch_encode_plus\n",
    "inputs = tokenizer.batch_encode_plus([\"Hello World\", \"你好世界\"], \n",
    "                                     max_length=64, truncation=True, padding=True,\n",
    "                                     return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.last_hidden_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
